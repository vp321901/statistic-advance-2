{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "luhnDn_986gK",
        "outputId": "01cca739-ac78-4b4b-c6cd-0bd08633fab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\nThe Probability Mass Function (PMF) is used for discrete random variables, providing the probability of each possible outcome.\\nFor example, when rolling a six-sided die, the PMF tells you the probability of rolling a 1, 2, 3, 4, 5, or 6.\\n\\nThe Probability Density Function (PDF) is used for continuous random variables and describes the likelihood of the variable falling within a certain range. Instead of giving the probability of a specific outcome, the PDF shows how likely different ranges of outcomes are. \\nFor example, in a normal distribution (like heights of people), the PDF shows that most heights cluster around the average, with fewer people being very short or very tall.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#answer:-1\n",
        "\"\"\"\"\n",
        "The Probability Mass Function (PMF) is used for discrete random variables, providing the probability of each possible outcome.\n",
        "For example, when rolling a six-sided die, the PMF tells you the probability of rolling a 1, 2, 3, 4, 5, or 6.\n",
        "\n",
        "The Probability Density Function (PDF) is used for continuous random variables and describes the likelihood of the variable falling within a certain range. Instead of giving the probability of a specific outcome, the PDF shows how likely different ranges of outcomes are.\n",
        "For example, in a normal distribution (like heights of people), the PDF shows that most heights cluster around the average, with fewer people being very short or very tall.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer:-2\n",
        "\"\"\"\n",
        "The Cumulative Distribution Function (CDF) shows the probability that a random variable is less than or equal to a certain value. It accumulates probabilities from the start of the distribution up to that point.\n",
        "\n",
        "Example:\n",
        "Imagine you have a jar of marbles in different colors. If you want to know the chance of picking a marble that is either red or blue, the CDF would tell you the total probability of picking any marble that is red or blue, including all other colors that come before them.\n",
        "\n",
        "Why CDF is Used:\n",
        "Probability Assessment: CDF helps to quickly determine the likelihood of a variable falling within a specific range.\n",
        "Comparison: It allows for easy comparison between different distributions.\n",
        "Threshold Analysis: CDF is useful for assessing the probability of exceeding certain values, which is important in fields like risk management and quality control.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "zCGP6I7S9U3t",
        "outputId": "aa09da8b-9b15-45a0-ea6e-d47a38086ab9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Cumulative Distribution Function (CDF) shows the probability that a random variable is less than or equal to a certain value. It accumulates probabilities from the start of the distribution up to that point.\\n\\nExample:\\nImagine you have a jar of marbles in different colors. If you want to know the chance of picking a marble that is either red or blue, the CDF would tell you the total probability of picking any marble that is red or blue, including all other colors that come before them.\\n\\nWhy CDF is Used:\\nProbability Assessment: CDF helps to quickly determine the likelihood of a variable falling within a specific range.\\nComparison: It allows for easy comparison between different distributions.\\nThreshold Analysis: CDF is useful for assessing the probability of exceeding certain values, which is important in fields like risk management and quality control.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer:-3\n",
        "\"\"\"The normal distribution is often used in various situations due to its properties. Here are some examples:\n",
        "\n",
        "Height and Weight: The distribution of heights and weights in a population tends to be normally distributed, where most individuals cluster around an average, with fewer people being extremely tall or short.\n",
        "\n",
        "Test Scores: Standardized test scores, like those from the SAT or IQ tests, are often modeled using a normal distribution. Most students score near the average, while very high or very low scores are less common.\n",
        "\n",
        "Measurement Errors: In scientific experiments, measurement errors are frequently normally distributed. Small errors are more common than large ones, resulting in a bell-shaped curve.\n",
        "\n",
        "Relation of Parameters to Shape:\n",
        "The normal distribution is characterized by two key parameters:\n",
        "\n",
        "Mean: This is the average value and determines the center of the distribution. If the mean shifts, the entire curve moves left or right.\n",
        "\n",
        "Standard Deviation: This measures the spread or width of the distribution. A smaller standard deviation means the data points are closer to the mean, resulting in a steeper curve, while a larger standard deviation results in a flatter curve.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "CLZ16jW--Ci8",
        "outputId": "c0f50eb5-9f2e-425e-82f5-e9daca74e1d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The normal distribution is often used in various situations due to its properties. Here are some examples:\\n\\nHeight and Weight: The distribution of heights and weights in a population tends to be normally distributed, where most individuals cluster around an average, with fewer people being extremely tall or short.\\n\\nTest Scores: Standardized test scores, like those from the SAT or IQ tests, are often modeled using a normal distribution. Most students score near the average, while very high or very low scores are less common.\\n\\nMeasurement Errors: In scientific experiments, measurement errors are frequently normally distributed. Small errors are more common than large ones, resulting in a bell-shaped curve.\\n\\nRelation of Parameters to Shape:\\nThe normal distribution is characterized by two key parameters:\\n\\nMean: This is the average value and determines the center of the distribution. If the mean shifts, the entire curve moves left or right.\\n\\nStandard Deviation: This measures the spread or width of the distribution. A smaller standard deviation means the data points are closer to the mean, resulting in a steeper curve, while a larger standard deviation results in a flatter curve.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer:-4\n",
        "\"\"\"The Normal Distribution is crucial in statistics and various fields due to its unique properties. Here’s why it is important:\n",
        "\n",
        "Foundation of Statistics: Many statistical methods, such as hypothesis testing and confidence intervals, assume that data is normally distributed. This allows for more straightforward analysis and interpretation.\n",
        "\n",
        "Central Limit Theorem: This theorem states that the distribution of the sample means approaches a normal distribution as the sample size increases, regardless of the original distribution. This is essential for making inferences about populations based on sample data.\n",
        "\n",
        "Predictability: Because many natural phenomena follow a normal distribution, it provides a reliable way to predict outcomes and assess probabilities.\n",
        "\n",
        "Real-Life Examples:\n",
        "Human Traits: Attributes like height, weight, and intelligence scores tend to follow a normal distribution, with most people clustering around the average and fewer at the extremes.\n",
        "\n",
        "Test Scores: Standardized tests, such as SAT or ACT scores, are often normally distributed, helping educators assess student performance relative to peers.\n",
        "\n",
        "Quality Control: In manufacturing, product measurements (like dimensions or weight) often follow a normal distribution. This helps companies maintain quality standards and identify defects.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "xba_izvG-M_g",
        "outputId": "ee376b88-6d1f-4bf5-e042-c2987be123fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Normal Distribution is crucial in statistics and various fields due to its unique properties. Here’s why it is important:\\n\\nFoundation of Statistics: Many statistical methods, such as hypothesis testing and confidence intervals, assume that data is normally distributed. This allows for more straightforward analysis and interpretation.\\n\\nCentral Limit Theorem: This theorem states that the distribution of the sample means approaches a normal distribution as the sample size increases, regardless of the original distribution. This is essential for making inferences about populations based on sample data.\\n\\nPredictability: Because many natural phenomena follow a normal distribution, it provides a reliable way to predict outcomes and assess probabilities.\\n\\nReal-Life Examples:\\nHuman Traits: Attributes like height, weight, and intelligence scores tend to follow a normal distribution, with most people clustering around the average and fewer at the extremes.\\n\\nTest Scores: Standardized tests, such as SAT or ACT scores, are often normally distributed, helping educators assess student performance relative to peers.\\n\\nQuality Control: In manufacturing, product measurements (like dimensions or weight) often follow a normal distribution. This helps companies maintain quality standards and identify defects.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer:-5\n",
        "\"\"\"The Bernoulli Distribution is a discrete probability distribution that describes a random experiment with only two possible outcomes: success and failure. It is characterized by a single parameter, which is the probability of success.\n",
        "\n",
        "Example:\n",
        "An example of a Bernoulli distribution is flipping a coin. If we define \"heads\" as success and \"tails\" as failure, then the probability of getting heads (success) is 0.5, and the probability of getting tails (failure) is also 0.5.\n",
        "\n",
        "Difference Between Bernoulli and Binomial Distribution:\n",
        "Bernoulli Distribution: Deals with a single trial or experiment, producing one outcome (success or failure). It’s a special case of the binomial distribution.\n",
        "\n",
        "Binomial Distribution: Involves multiple independent Bernoulli trials (n trials), measuring the number of successes in those trials. It has two parameters: the number of trials and the probability of success.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "aE9N03BC-XTh",
        "outputId": "dd1d937a-73dc-43f9-9f81-84503cdf471c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Bernoulli Distribution is a discrete probability distribution that describes a random experiment with only two possible outcomes: success and failure. It is characterized by a single parameter, which is the probability of success.\\n\\nExample:\\nAn example of a Bernoulli distribution is flipping a coin. If we define \"heads\" as success and \"tails\" as failure, then the probability of getting heads (success) is 0.5, and the probability of getting tails (failure) is also 0.5.\\n\\nDifference Between Bernoulli and Binomial Distribution:\\nBernoulli Distribution: Deals with a single trial or experiment, producing one outcome (success or failure). It’s a special case of the binomial distribution.\\n\\nBinomial Distribution: Involves multiple independent Bernoulli trials (n trials), measuring the number of successes in those trials. It has two parameters: the number of trials and the probability of success.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer:-6\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Given values\n",
        "mean = 50\n",
        "std_dev = 10\n",
        "value = 60\n",
        "\n",
        "# Calculate the z-score\n",
        "z_score = (value - mean) / std_dev\n",
        "\n",
        "# Find the probability of getting a value less than 60 (using CDF)\n",
        "prob_less_than_60 = stats.norm.cdf(z_score)\n",
        "\n",
        "# Probability of getting a value greater than 60\n",
        "prob_greater_than_60 = 1 - prob_less_than_60\n",
        "print(prob_greater_than_60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEjmDuQ2CbYD",
        "outputId": "fab2a391-6c09-436c-9056-cc0ad86f92f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15865525393145707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer:-7\n",
        "\"\"\"\n",
        "The Uniform Distribution is a type of probability distribution where every outcome in a given range is equally likely to occur. There are two types: discrete and continuous. In a continuous uniform distribution, any value within a specified interval has the same probability of being chosen.\n",
        "\n",
        "Example:\n",
        "Consider a spinner that can land anywhere between 0 and 1. Since every point in that range is equally likely, the probability of landing at any specific point is the same. This is a continuous uniform distribution.\n",
        "\n",
        "In real life, uniform distributions can model random selection from a range where every outcome has an equal chance, like picking a random number between 1 and 10.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "NuZB0clhXiV5",
        "outputId": "4d0de8ba-a3c7-4e83-8a59-fa1a8e31d0ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Uniform Distribution is a type of probability distribution where every outcome in a given range is equally likely to occur. There are two types: discrete and continuous. In a continuous uniform distribution, any value within a specified interval has the same probability of being chosen.\\n\\nExample:\\nConsider a spinner that can land anywhere between 0 and 1. Since every point in that range is equally likely, the probability of landing at any specific point is the same. This is a continuous uniform distribution.\\n\\nIn real life, uniform distributions can model random selection from a range where every outcome has an equal chance, like picking a random number between 1 and 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer:-8\n",
        "\"\"\"A z-score is a measure that describes how far a specific data point is from the mean of a dataset, in terms of standard deviations.\n",
        "It tells you how many standard deviations above or below the mean a value lies.\n",
        "\n",
        "Importance of the z-score:\n",
        "Standardization: Z-scores standardize different data sets, allowing you to compare them even if they have different units or scales.\n",
        "Outlier Detection: Z-scores help identify outliers, as extreme z-scores (positive or negative) indicate values far from the average.\n",
        "Probability Calculations: In a normal distribution, z-scores are used to determine probabilities and percentiles, which is crucial for hypothesis testing.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "sCLLZMvY6syG",
        "outputId": "9ba24383-7ff0-4e03-80c7-04cb1e0b96d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A z-score is a measure that describes how far a specific data point is from the mean of a dataset, in terms of standard deviations. \\nIt tells you how many standard deviations above or below the mean a value lies.\\n\\nImportance of the z-score:\\nStandardization: Z-scores standardize different data sets, allowing you to compare them even if they have different units or scales.\\nOutlier Detection: Z-scores help identify outliers, as extreme z-scores (positive or negative) indicate values far from the average.\\nProbability Calculations: In a normal distribution, z-scores are used to determine probabilities and percentiles, which is crucial for hypothesis testing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer:-9\n",
        "\"\"\"The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's original distribution, as long as the samples are independent and identically distributed.\n",
        "\n",
        "Significance of the Central Limit Theorem:\n",
        "Foundation for Inference: CLT allows us to make inferences about a population from a sample, especially when using large samples.\n",
        "Approximation of Distributions: It justifies using the normal distribution for hypothesis testing and confidence intervals, even when the data isn't normally distributed, as long as the sample size is large enough.\n",
        "Practical Application: It simplifies statistical analysis, as normal distribution tools can be applied to various real-world problems regardless of the population's original shape.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "HbU1USdR66nU",
        "outputId": "ddb4b9c0-1c97-45e2-cbad-80f82ff77dbb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's original distribution, as long as the samples are independent and identically distributed.\\n\\nSignificance of the Central Limit Theorem:\\nFoundation for Inference: CLT allows us to make inferences about a population from a sample, especially when using large samples.\\nApproximation of Distributions: It justifies using the normal distribution for hypothesis testing and confidence intervals, even when the data isn't normally distributed, as long as the sample size is large enough.\\nPractical Application: It simplifies statistical analysis, as normal distribution tools can be applied to various real-world problems regardless of the population's original shape.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer:-10\n",
        "\"\"\"The Central Limit Theorem (CLT) relies on the following key assumptions:\n",
        "\n",
        "1:---Independence: The data points in the sample must be independent of each other. This means that the outcome of one observation should not influence the outcome of another.\n",
        "\n",
        "2:---Sample Size: The sample size should be sufficiently large. Typically, a sample size of 30 or more is considered adequate for the CLT to hold, though larger samples provide better approximations.\n",
        "\n",
        "3:---Identically Distributed: The population from which the sample is drawn should have the same distribution (i.e., each data point should come from the same probability distribution).\"\"\""
      ],
      "metadata": {
        "id": "2qnH8jzU7Q8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}